{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ceed888-ab59-460f-be8e-cf2e4eba5c51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_stata(\"anomalies.dta\")\n",
    "\n",
    "# Generate yyyymm variable\n",
    "data['yyyymm'] = 100 * data['year'] + data['month']\n",
    "\n",
    "# Collapse data by global and anomaly\n",
    "collapsed_data = data.groupby(['global', 'anomaly']).agg(\n",
    "    ret=('ret', 'mean'),\n",
    "    sd=('ret', np.std),\n",
    "    semean=('ret', lambda x: np.std(x) / np.sqrt(len(x))),\n",
    "    n=('ret', 'count'),\n",
    "    min_ret=('ret', 'min'),\n",
    "    yyyymm=('yyyymm', lambda x: x.iloc[0])  # Take the first yyyymm value as representative\n",
    ").reset_index()\n",
    "\n",
    "# Calculate t-statistic\n",
    "collapsed_data['tstat'] = collapsed_data['ret'] / collapsed_data['semean']\n",
    "\n",
    "# Multiply ret by 12 and sd by sqrt(12)\n",
    "collapsed_data['ret'] *= 12\n",
    "collapsed_data['sd'] *= np.sqrt(12)\n",
    "\n",
    "# Format columns\n",
    "collapsed_data['ret'] = collapsed_data['ret'].map(\"{:.2f}\".format)\n",
    "collapsed_data['sd'] = collapsed_data['sd'].map(\"{:.2f}\".format)\n",
    "collapsed_data['tstat'] = collapsed_data['tstat'].map(\"{:.2f}\".format)\n",
    "\n",
    "# Keep relevant columns and reorder\n",
    "collapsed_data = collapsed_data[['anomaly', 'yyyymm', 'ret', 'sd', 'tstat']]\n",
    "\n",
    "print(collapsed_data)\n",
    "\n",
    "# ===============================================================================\n",
    "# Table II and AI: factor returns conditional of their past returns \n",
    "# ===============================================================================\n",
    "\n",
    "# Generate flag column\n",
    "data['flag'] = np.sign(data['MA'])\n",
    "data['flag'].replace(-1, 0, inplace=True)\n",
    "\n",
    "# Individual time series regressions of factor returns on their past 12 month returns\n",
    "reg_results = []\n",
    "\n",
    "for group, group_data in data.groupby('global'):\n",
    "    if group_data['Pan'].nunique() == 1:\n",
    "        model = sm.OLS(group_data['ret'], sm.add_constant(group_data['MA'])).fit()\n",
    "    else:\n",
    "        model = sm.OLS(group_data['ret'], sm.add_constant(group_data['MA'])).fit(cov_type='cluster', cov_kwds={'groups': group_data['time']})\n",
    "    \n",
    "    a0 = model.params['const']\n",
    "    a0t = model.tvalues['const']\n",
    "    b0 = model.params['MA']\n",
    "    b0t = model.tvalues['MA']\n",
    "    \n",
    "    model = sm.OLS(group_data['ret'], sm.add_constant(group_data['flag'])).fit()\n",
    "    \n",
    "    a1 = model.params['const']\n",
    "    a1t = model.tvalues['const']\n",
    "    b1 = model.params['flag']\n",
    "    b1t = model.tvalues['flag']\n",
    "    \n",
    "    reg_results.append({\n",
    "        'global': group,\n",
    "        'a0': a0, 'a0t': a0t, 'b0': b0, 'b0t': b0t,\n",
    "        'a1': a1, 'a1t': a1t, 'b1': b1, 'b1t': b1t\n",
    "    })\n",
    "\n",
    "# Collapse results\n",
    "reg_results_df = pd.DataFrame(reg_results)\n",
    "collapsed_reg_results = reg_results_df.groupby(['global', 'anomaly']).mean().reset_index()\n",
    "\n",
    "print(collapsed_reg_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57829acd-6172-44a4-ad94-d587d04eab8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           mean_tsmom     tstat\n",
      "tsmom1       0.192298  7.069135\n",
      "tsmom2       0.126633  5.227156\n",
      "tsmom3       0.101961  5.019928\n",
      "tsmom4       0.100712  4.048101\n",
      "tsmom5       0.072299  2.506116\n",
      "sd_tsmom1    0.192298  7.069135\n",
      "sd_tsmom2    0.126633  5.227156\n",
      "sd_tsmom3    0.101961  5.019928\n",
      "sd_tsmom4    0.100712  4.048101\n",
      "sd_tsmom5    0.072299  2.506116\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'period'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(total_sample_stats[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_tsmom\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtstat\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Panel A - Total sample statistics\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m total_sample_stats \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mperiod\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39magg(\n\u001b[1;32m     24\u001b[0m     mean_tsmom\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtsmom\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     25\u001b[0m     mean_sd_tsmom\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msd_tsmom\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     26\u001b[0m     count_N\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mN\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     27\u001b[0m )\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Panel A - Statistics in the first half and second half\u001b[39;00m\n\u001b[1;32m     30\u001b[0m period_stats \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mperiod\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubset\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39magg(\n\u001b[1;32m     31\u001b[0m     mean_tsmom\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtsmom\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     32\u001b[0m     mean_sd_tsmom\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msd_tsmom\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     33\u001b[0m     count_N\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mN\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     34\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:8869\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   8866\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   8867\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to supply one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 8869\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrameGroupBy(\n\u001b[1;32m   8870\u001b[0m     obj\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   8871\u001b[0m     keys\u001b[38;5;241m=\u001b[39mby,\n\u001b[1;32m   8872\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m   8873\u001b[0m     level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[1;32m   8874\u001b[0m     as_index\u001b[38;5;241m=\u001b[39mas_index,\n\u001b[1;32m   8875\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[1;32m   8876\u001b[0m     group_keys\u001b[38;5;241m=\u001b[39mgroup_keys,\n\u001b[1;32m   8877\u001b[0m     observed\u001b[38;5;241m=\u001b[39mobserved,\n\u001b[1;32m   8878\u001b[0m     dropna\u001b[38;5;241m=\u001b[39mdropna,\n\u001b[1;32m   8879\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:1278\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   1275\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna \u001b[38;5;241m=\u001b[39m dropna\n\u001b[1;32m   1277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1278\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m get_grouper(\n\u001b[1;32m   1279\u001b[0m         obj,\n\u001b[1;32m   1280\u001b[0m         keys,\n\u001b[1;32m   1281\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m   1282\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[1;32m   1283\u001b[0m         sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[1;32m   1284\u001b[0m         observed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default \u001b[38;5;28;01melse\u001b[39;00m observed,\n\u001b[1;32m   1285\u001b[0m         dropna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna,\n\u001b[1;32m   1286\u001b[0m     )\n\u001b[1;32m   1288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[1;32m   1289\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping\u001b[38;5;241m.\u001b[39m_passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper\u001b[38;5;241m.\u001b[39mgroupings):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/groupby/grouper.py:1009\u001b[0m, in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[1;32m   1007\u001b[0m         in_axis, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1008\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1009\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1011\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[1;32m   1012\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'period'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_stata(\"oos_tsmom_scs.dta\")\n",
    "\n",
    "# Convert tsmom variables to percentage\n",
    "tsmom_cols = [col for col in data.columns if col.startswith('tsmom')]\n",
    "data[tsmom_cols] *= 100\n",
    "\n",
    "# Calculate standard deviations\n",
    "for var in tsmom_cols:\n",
    "    data[f'sd_{var}'] = data[var]\n",
    "\n",
    "# Panel A - Total sample statistics\n",
    "total_sample_stats = data[tsmom_cols + [f'sd_{col}' for col in tsmom_cols]].describe().transpose()[['mean', 'std', 'count']]\n",
    "total_sample_stats.columns = ['mean_tsmom', 'mean_sd_tsmom', 'count_N']\n",
    "total_sample_stats['sharpe'] = total_sample_stats['mean_tsmom'] / total_sample_stats['mean_sd_tsmom']\n",
    "total_sample_stats['tstat'] = np.sqrt(total_sample_stats['count_N']) * (total_sample_stats['mean_tsmom'] / total_sample_stats['mean_sd_tsmom'])\n",
    "print(total_sample_stats[['mean_tsmom', 'tstat']])\n",
    "\n",
    "# Panel A - Total sample statistics\n",
    "total_sample_stats = data.groupby('period').agg(\n",
    "    mean_tsmom=('tsmom', 'mean'),\n",
    "    mean_sd_tsmom=('sd_tsmom', 'mean'),\n",
    "    count_N=('N', 'first')\n",
    ")\n",
    "\n",
    "# Panel A - Statistics in the first half and second half\n",
    "period_stats = data.groupby(['period', 'subset']).agg(\n",
    "    mean_tsmom=('tsmom', 'mean'),\n",
    "    mean_sd_tsmom=('sd_tsmom', 'mean'),\n",
    "    count_N=('N', 'first')\n",
    ")\n",
    "\n",
    "period_stats['sharpe'] = period_stats['mean_tsmom'] / period_stats['mean_sd_tsmom']\n",
    "period_stats['tstat'] = np.sqrt(period_stats['count_N']) * (period_stats['mean_tsmom'] / period_stats['mean_sd_tsmom'])\n",
    "print(period_stats[['mean_tsmom', 'tstat']])\n",
    "\n",
    "# Panel B and C - Spanning tests\n",
    "factor_data = pd.read_stata(\"fffactors.dta\")\n",
    "data = pd.merge(data, factor_data, on='yyyymm')\n",
    "\n",
    "# Panel B: Explaining factor momentum in low-eigenvalue PC factors\n",
    "for i in range(2, 6):\n",
    "    formula = f'tsmom{i} ~ mktrf + smb + hml + rmw + cma + tsmom1 + period'\n",
    "    reg_other = sm.OLS.from_formula(formula, data=data).fit()\n",
    "    print(reg_other.summary())\n",
    "\n",
    "# Panel C: Explaining factor momentum in high-eigenvalue PC factors\n",
    "formula = 'tsmom1 ~ mktrf + smb + hml + rmw + cma + tsmom2 + tsmom3 + tsmom4 + tsmom5 + period'\n",
    "reg_main = sm.OLS.from_formula(formula, data=data).fit()\n",
    "print(reg_main.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c86eee-9849-41bc-b820-414840885baf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import pearsonr, norm\n",
    "from math import atanh, sqrt  # Import the necessary functions\n",
    "# Load the dataset and clean it\n",
    "data = pd.read_stata(\"anomalies.dta\")\n",
    "data = data[~data['anomaly'].isin([\"umd\", \"glumd\"])]  # Drop rows where anomaly is \"umd\" or \"glumd\"\n",
    "\n",
    "# Generate moving average of returns over a 12-month window\n",
    "data['MA'] = data.groupby('global')['ret'].transform(lambda x: x.rolling(window=12).mean())\n",
    "\n",
    "# Drop rows where moving average contains NaN values\n",
    "data = data.dropna(subset=['MA'])\n",
    "\n",
    "# Merge with FactorUMD.dta\n",
    "factor_data = pd.read_stata(\"FactorUMD.dta\")\n",
    "merged_data = pd.merge(data, factor_data, on=['year', 'month'])\n",
    "\n",
    "# Group by 'Pan' (or 'global' in Python) and calculate correlations for different conditions\n",
    "groups = merged_data.groupby('global')\n",
    "\n",
    "correlations = []\n",
    "for name, group in groups:\n",
    "    corr_all, _ = pearsonr(group['ret'], group['umd'])  # Adjust column names from 'AnomalyRet' to 'ret'\n",
    "    corr_up, _ = pearsonr(group[group['MA'] > 0]['ret'], group[group['MA'] > 0]['umd'])\n",
    "    corr_down, _ = pearsonr(group[group['MA'] < 0]['ret'], group[group['MA'] < 0]['umd'])\n",
    "    corr_cond, _ = pearsonr(group['MA'] * group['ret'], group['umd'])  # Calculate conditional correlation\n",
    "    \n",
    "    # Calculate Fisher's Z-test for conditional vs. unconditional correlations\n",
    "    mu_Z = (atanh(corr_cond) - atanh(corr_all))\n",
    "    sigma_Z = sqrt(1/(len(group) - 3) + 1/(len(group) - 3))\n",
    "    Z = mu_Z / sigma_Z\n",
    "    pvalue = 2 * norm.cdf(-abs(Z))\n",
    "    \n",
    "    # Calculate unbalanced Fisher's Z-test for positive vs. negative moving averages\n",
    "    mu_Z_un = (atanh(corr_up) - atanh(corr_down))\n",
    "    sigma_Z_un = sqrt(1/(len(group[group['MA'] > 0]) - 3) + 1/(len(group[group['MA'] < 0]) - 3))\n",
    "    Z_un = mu_Z_un / sigma_Z_un\n",
    "    pvalue_un = 2 * norm.cdf(-abs(Z_un))\n",
    "    \n",
    "    correlations.append({\n",
    "        'global': name,\n",
    "        'corr_all': corr_all,\n",
    "        'corr_up': corr_up,\n",
    "        'corr_down': corr_down,\n",
    "        'corr_cond': corr_cond,\n",
    "        'Z': Z,\n",
    "        'pvalue': pvalue,\n",
    "        'Z_un': Z_un,\n",
    "        'pvalue_un': pvalue_un\n",
    "    })\n",
    "\n",
    "correlations_df = pd.DataFrame(correlations)\n",
    "print(correlations_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
