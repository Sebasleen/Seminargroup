{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c3b02ed9dd222dd"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-26T13:35:14.725427Z",
     "start_time": "2024-02-26T13:35:14.700406Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Table 1\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1ed0fca218438e6d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loading data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b7d7850c72b3792a"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ac' 'bab' 'cfp' 'cma' 'ep' 'hml' 'liq' 'ltrev' 'nsi' 'qmj' 'rmw' 'rvar'\n",
      " 'smb' 'strev' 'umd' 'glbab' 'glcma' 'glhml' 'glqmj' 'glrmw' 'glsmb'\n",
      " 'glumd']\n",
      "       year  month anomaly    ret   time  global\n",
      "0      1963      7      ac  2.170   42.0     0.0\n",
      "1      1963      8      ac -0.197   43.0     0.0\n",
      "2      1963      9      ac  0.600   44.0     0.0\n",
      "3      1963     10      ac  6.463   45.0     0.0\n",
      "4      1963     11      ac -2.260   46.0     0.0\n",
      "...     ...    ...     ...    ...    ...     ...\n",
      "10111  2019      8     umd  7.600  715.0     0.0\n",
      "10112  2019      9     umd -6.850  716.0     0.0\n",
      "10113  2019     10     umd  0.240  717.0     0.0\n",
      "10114  2019     11     umd -2.620  718.0     0.0\n",
      "10115  2019     12     umd -2.130  719.0     0.0\n",
      "\n",
      "[10116 rows x 6 columns]\n",
      "       year  month anomaly       ret   time  global\n",
      "10116  1987      2   glbab  2.236918  325.0     1.0\n",
      "10117  1987      3   glbab  1.828450  326.0     1.0\n",
      "10118  1987      4   glbab -5.521739  327.0     1.0\n",
      "10119  1987      5   glbab -0.513814  328.0     1.0\n",
      "10120  1987      6   glbab  1.579217  329.0     1.0\n",
      "...     ...    ...     ...       ...    ...     ...\n",
      "12638  2019      8   glumd  2.990000  715.0     1.0\n",
      "12639  2019      9   glumd -3.260000  716.0     1.0\n",
      "12640  2019     10   glumd -0.940000  717.0     1.0\n",
      "12641  2019     11   glumd  0.000000  718.0     1.0\n",
      "12642  2019     12   glumd  0.740000  719.0     1.0\n",
      "\n",
      "[2527 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "url = 'https://github.com/Sebasleen/Seminargroup/raw/Seminar/Data/anomalies.dta'\n",
    "\n",
    "Anomalies = pd.read_stata(url)\n",
    "\n",
    "# display unique values in the 'anomaly' column\n",
    "print(Anomalies['anomaly'].unique())\n",
    "\n",
    "# delete the global factors from the dataframe and create Anomalies US\n",
    "column_name = 'anomaly'\n",
    "values_to_dropUS = ['glbab', 'glcma', 'glhml', 'glqmj', 'glrmw', 'glsmb', 'glumd']\n",
    "ElementsUS = Anomalies[column_name].isin(values_to_dropUS)\n",
    "Anomalies_US = Anomalies[~ElementsUS]\n",
    "\n",
    "# delete the US factors from dataframe and create Anomalies Global \n",
    "column_name = 'anomaly'\n",
    "values_to_dropGF = ['ac', 'bab', 'cfp', 'cma', 'ep', 'hml', 'liq', 'ltrev', 'nsi', 'qmj', 'rmw', 'rvar',\n",
    "                    'smb', 'strev', 'umd']\n",
    "ElementsGF = Anomalies[column_name].isin(values_to_dropGF)\n",
    "Anomalies_GF = Anomalies[~ElementsGF]\n",
    "\n",
    "# print both anomalies US and anomalies global \n",
    "print(Anomalies_US)\n",
    "print(Anomalies_GF)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T13:12:17.659382Z",
     "start_time": "2024-02-26T13:12:16.740681Z"
    }
   },
   "id": "aefa9a33ec9759a5",
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "### replicating table 1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "61f2b93f47c09c62"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### US factors"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c3b4c916e084c319"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   anomaly  Mean     SD T-value\n",
      "0       ac  2.8%   6.6%    3.19\n",
      "1      bab  9.8%  11.2%    6.55\n",
      "2      cfp  3.4%   8.6%    2.94\n",
      "3      cma  3.3%   6.9%    3.59\n",
      "4       ep  3.5%   8.9%    2.95\n",
      "5      hml  3.6%   9.7%    2.82\n",
      "6      liq  4.4%  11.6%    2.77\n",
      "7    ltrev  2.5%   8.7%    2.16\n",
      "8      nsi  2.8%   8.2%    2.52\n",
      "9      qmj  4.6%   7.7%    4.47\n",
      "10     rmw  3.1%   7.5%    3.13\n",
      "11    rvar  1.6%  17.3%    0.68\n",
      "12     smb  2.7%  10.4%    1.97\n",
      "13   strev  6.0%  10.6%    4.21\n",
      "14     umd  7.8%  14.5%    4.02\n"
     ]
    }
   ],
   "source": [
    "# calculate the mean and stand deviation of US factors\n",
    "AnomaliesUS = Anomalies_US.groupby(['anomaly']).agg({'ret': ['mean', 'std', 'count']}).reset_index()\n",
    "AnomaliesUS = Anomalies_US.pivot_table(index='anomaly', values='ret', aggfunc=['mean', 'std', 'count'])\n",
    "AnomaliesUS.columns = ['Mean', 'SD', 'ret_number']\n",
    "AnomaliesUS.reset_index(inplace=True)\n",
    "AnomaliesUS.columns = ['anomaly', 'Mean', 'SD', 'ret_number']\n",
    "\n",
    "# calculate additional statistics\n",
    "AnomaliesUS['ret_semean'] = AnomaliesUS['SD'] / np.sqrt(AnomaliesUS['ret_number'])\n",
    "\n",
    "# multiply by 12 to create annualized returns\n",
    "AnomaliesUS['ret'] = AnomaliesUS['Mean'] * 12\n",
    "\n",
    "# multiply by sqrt(12) to create annualized standard deviation\n",
    "AnomaliesUS['sd'] = AnomaliesUS['SD'] * np.sqrt(12)\n",
    "\n",
    "# calculate the t-stat by dividing the return by the standard error of the mean. Divide by 12 to annualize it\n",
    "AnomaliesUS['tstat'] = AnomaliesUS['ret'] / AnomaliesUS['ret_semean'] /12\n",
    "\n",
    "# format the table to correct decimals\n",
    "AnomaliesUS[['Mean']] = AnomaliesUS[['ret']].apply(lambda x: x.map(\"{:.1f}%\".format))\n",
    "AnomaliesUS[['SD']] = AnomaliesUS[['sd']].apply(lambda x: x.map(\"{:.1f}%\".format))\n",
    "AnomaliesUS[['T-value']] = AnomaliesUS[['tstat']].apply(lambda x: x.map(\"{:.2f}\".format))\n",
    "\n",
    "print(AnomaliesUS[['anomaly','Mean','SD','T-value']])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T13:12:32.874029Z",
     "start_time": "2024-02-26T13:12:32.830780Z"
    }
   },
   "id": "66347171583346c7",
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Global factors"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7f970bbebcafdd90"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  anomaly  Mean     SD T-value\n",
      "0   glbab  9.6%   9.7%    5.70\n",
      "1   glcma  1.9%   6.0%    1.74\n",
      "2   glhml  4.0%   7.4%    2.92\n",
      "3   glqmj  6.2%   6.8%    5.06\n",
      "4   glrmw  4.3%   4.7%    4.91\n",
      "5   glsmb  1.1%   7.1%    0.83\n",
      "6   glumd  7.9%  12.1%    3.54\n"
     ]
    }
   ],
   "source": [
    "# calculate the mean and stand deviation of Global factors\n",
    "AnomaliesGF = Anomalies_GF.groupby(['anomaly']).agg({'ret': ['mean', 'std', 'count']}).reset_index()\n",
    "AnomaliesGF = Anomalies_GF.pivot_table(index='anomaly', values='ret', aggfunc=['mean', 'std', 'count'])\n",
    "AnomaliesGF.columns = ['Mean', 'SD', 'ret_number']\n",
    "AnomaliesGF.reset_index(inplace=True)\n",
    "AnomaliesGF.columns = ['anomaly', 'Mean', 'SD', 'ret_number']\n",
    "\n",
    "# calculate additional statistics\n",
    "AnomaliesGF['ret_semean'] = AnomaliesGF['SD'] / np.sqrt(AnomaliesGF['ret_number'])\n",
    "\n",
    "# multiply by 12 to create annualized returns\n",
    "AnomaliesGF['ret'] = AnomaliesGF['Mean'] * 12\n",
    "\n",
    "# multiply by sqrt(12) to create annualized standard deviation\n",
    "AnomaliesGF['sd'] = AnomaliesGF['SD'] * np.sqrt(12)\n",
    "\n",
    "# calculate the t-stat by dividing the return by the standard error of the mean. Divide by 12 to annualize it\n",
    "AnomaliesGF['tstat'] = AnomaliesGF['ret'] / AnomaliesGF['ret_semean'] /12\n",
    "\n",
    "# format the table to correct decimals\n",
    "AnomaliesGF[['Mean']] = AnomaliesGF[['ret']].apply(lambda x: x.map(\"{:.1f}%\".format))\n",
    "AnomaliesGF[['SD']] = AnomaliesGF[['sd']].apply(lambda x: x.map(\"{:.1f}%\".format))\n",
    "AnomaliesGF[['T-value']] = AnomaliesGF[['tstat']].apply(lambda x: x.map(\"{:.2f}\".format))\n",
    "\n",
    "print(AnomaliesGF[['anomaly','Mean','SD','T-value']])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T13:12:42.065180Z",
     "start_time": "2024-02-26T13:12:42.044718Z"
    }
   },
   "id": "bbd214b9e39f7b82",
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Table 2 "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6a16892a0e1af284"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### replicating table 2 (uses the same dataset as table 1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6a5369eb282369a4"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Anomaly     Alpha  T-stat_Alpha     Slope  T-stat_Slope\n",
      "0       ac  0.150195      1.184450  0.101410      0.649822\n",
      "1      bab -0.221412     -0.632211  1.319041      3.534152\n",
      "2      cfp  0.127745      0.781292  0.235454      1.157989\n",
      "3      cma  0.120082      0.974474  0.244693      1.545819\n",
      "4       ep  0.101357      0.616107  0.302075      1.458207\n",
      "5      hml  0.038477      0.204762  0.410255      1.780679\n",
      "6      liq  0.157215      0.741922  0.356063      1.291807\n",
      "7    ltrev -0.252989     -1.663307  0.757680      3.850110\n",
      "8      nsi  0.172982      1.324451  0.089249      0.486779\n",
      "9      qmj  0.086832      0.650364  0.434757      2.507550\n",
      "10     rmw  0.040360      0.222250  0.337185      1.673841\n",
      "11    rvar -0.463569     -1.638345  1.061609      2.737366\n",
      "12     smb -0.104191     -0.615583  0.583455      2.508982\n",
      "13   strev  0.485098      1.427336  0.013888      0.038600\n",
      "14     umd  0.716042      2.697340 -0.094969     -0.288098\n",
      "15   glbab  0.190820      0.577502  0.837610      2.303918\n",
      "16   glcma -0.064014     -0.408285  0.382064      1.944285\n",
      "17   glhml  0.035556      0.150752  0.471689      1.770057\n",
      "18   glqmj  0.394512      1.761234  0.124643      0.492025\n",
      "19   glrmw  0.137826      1.033410  0.256716      1.616411\n",
      "20   glsmb -0.063285     -0.388832  0.284797      1.325669\n",
      "21   glumd  0.668710      1.774142  0.017124      0.039403\n"
     ]
    }
   ],
   "source": [
    "# create an empty list to store results\n",
    "results_list = []\n",
    "\n",
    "# create a loop which iterates over each anomly in our dataset \n",
    "for anomaly in Anomalies['anomaly'].unique():\n",
    "    subset = Anomalies[Anomalies['anomaly'] == anomaly]\n",
    "    subset = subset.sort_values(by='time')\n",
    "\n",
    "    # create a binary variable for positive returns in the past 12 months (the signal variable)\n",
    "    subset['positive_return'] = subset['ret'].rolling(window=12, min_periods=12).mean().shift(1) > 0\n",
    "\n",
    "    # drop the first 12 observations in the subset after the rolling window has been applied (so dropping N/A values)\n",
    "    subset = subset.iloc[12:]\n",
    "\n",
    "    # select our OLS model and fit our data\n",
    "    y = subset['ret']\n",
    "    X = sm.add_constant(subset['positive_return'].astype(int))\n",
    "    model = sm.OLS(y, X)\n",
    "    \n",
    "    # select the correct covariance type (as used in the paper)\n",
    "    results = model.fit(cov_type='cluster', cov_kwds={'groups': subset['time']})\n",
    "\n",
    "    # append the results to our dictionary to create the results\n",
    "    results_list.append({\n",
    "        'anomaly': anomaly,\n",
    "        'alpha': results.params['const'],\n",
    "        'T-stat_alpha': results.tvalues['const'],\n",
    "        'slope': results.params['positive_return'],\n",
    "        'T-stat_slope': results.tvalues['positive_return'],\n",
    "    })\n",
    "\n",
    "results_table = pd.DataFrame(results_list)\n",
    "print(results_table)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T13:22:38.886376Z",
     "start_time": "2024-02-26T13:22:38.813337Z"
    }
   },
   "id": "d64fbe7d50f9ec9",
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Table 3"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5405d5744d09b948"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loading dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f19fe09105a82214"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'freq_to_period_freqstr' from 'pandas._libs.tslibs.dtypes' (/Users/sjoerd/anaconda3/lib/python3.11/site-packages/pandas/_libs/tslibs/dtypes.cpython-311-darwin.so)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[20], line 28\u001B[0m\n\u001B[1;32m     24\u001B[0m factors \u001B[38;5;241m=\u001B[39m [col \u001B[38;5;28;01mfor\u001B[39;00m col \u001B[38;5;129;01min\u001B[39;00m r_daily\u001B[38;5;241m.\u001B[39mcolumns \u001B[38;5;28;01mif\u001B[39;00m col\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mr_\u001B[39m\u001B[38;5;124m'\u001B[39m)]\n\u001B[1;32m     26\u001B[0m \u001B[38;5;66;03m# create a monthly return dataframe for later analysis purposes (by summing the daily returns)\u001B[39;00m\n\u001B[0;32m---> 28\u001B[0m r_monthly \u001B[38;5;241m=\u001B[39m r_daily\u001B[38;5;241m.\u001B[39mresample(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mM\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39msum()\n\u001B[1;32m     29\u001B[0m r_monthly\u001B[38;5;241m.\u001B[39mindex \u001B[38;5;241m=\u001B[39m r_monthly\u001B[38;5;241m.\u001B[39mindex\u001B[38;5;241m.\u001B[39mstrftime(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mY-\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mm\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:10994\u001B[0m, in \u001B[0;36mresample\u001B[0;34m(self, rule, axis, closed, label, convention, kind, on, level, origin, offset, group_keys)\u001B[0m\n\u001B[1;32m  10962\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcorr\u001B[39m(\n\u001B[1;32m  10963\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m  10964\u001B[0m     method: CorrelationMethod \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpearson\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m  10965\u001B[0m     min_periods: \u001B[38;5;28mint\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m  10966\u001B[0m     numeric_only: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m  10967\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame:\n\u001B[1;32m  10968\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m  10969\u001B[0m \u001B[38;5;124;03m    Compute pairwise correlation of columns, excluding NA/null values.\u001B[39;00m\n\u001B[1;32m  10970\u001B[0m \n\u001B[1;32m  10971\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[1;32m  10972\u001B[0m \u001B[38;5;124;03m    ----------\u001B[39;00m\n\u001B[1;32m  10973\u001B[0m \u001B[38;5;124;03m    method : {'pearson', 'kendall', 'spearman'} or callable\u001B[39;00m\n\u001B[1;32m  10974\u001B[0m \u001B[38;5;124;03m        Method of correlation:\u001B[39;00m\n\u001B[1;32m  10975\u001B[0m \n\u001B[1;32m  10976\u001B[0m \u001B[38;5;124;03m        * pearson : standard correlation coefficient\u001B[39;00m\n\u001B[1;32m  10977\u001B[0m \u001B[38;5;124;03m        * kendall : Kendall Tau correlation coefficient\u001B[39;00m\n\u001B[1;32m  10978\u001B[0m \u001B[38;5;124;03m        * spearman : Spearman rank correlation\u001B[39;00m\n\u001B[1;32m  10979\u001B[0m \u001B[38;5;124;03m        * callable: callable with input two 1d ndarrays\u001B[39;00m\n\u001B[1;32m  10980\u001B[0m \u001B[38;5;124;03m            and returning a float. Note that the returned matrix from corr\u001B[39;00m\n\u001B[1;32m  10981\u001B[0m \u001B[38;5;124;03m            will have 1 along the diagonals and will be symmetric\u001B[39;00m\n\u001B[1;32m  10982\u001B[0m \u001B[38;5;124;03m            regardless of the callable's behavior.\u001B[39;00m\n\u001B[1;32m  10983\u001B[0m \u001B[38;5;124;03m    min_periods : int, optional\u001B[39;00m\n\u001B[1;32m  10984\u001B[0m \u001B[38;5;124;03m        Minimum number of observations required per pair of columns\u001B[39;00m\n\u001B[1;32m  10985\u001B[0m \u001B[38;5;124;03m        to have a valid result. Currently only available for Pearson\u001B[39;00m\n\u001B[1;32m  10986\u001B[0m \u001B[38;5;124;03m        and Spearman correlation.\u001B[39;00m\n\u001B[1;32m  10987\u001B[0m \u001B[38;5;124;03m    numeric_only : bool, default False\u001B[39;00m\n\u001B[1;32m  10988\u001B[0m \u001B[38;5;124;03m        Include only `float`, `int` or `boolean` data.\u001B[39;00m\n\u001B[1;32m  10989\u001B[0m \n\u001B[1;32m  10990\u001B[0m \u001B[38;5;124;03m        .. versionadded:: 1.5.0\u001B[39;00m\n\u001B[1;32m  10991\u001B[0m \n\u001B[1;32m  10992\u001B[0m \u001B[38;5;124;03m        .. versionchanged:: 2.0.0\u001B[39;00m\n\u001B[1;32m  10993\u001B[0m \u001B[38;5;124;03m            The default value of ``numeric_only`` is now ``False``.\u001B[39;00m\n\u001B[0;32m> 10994\u001B[0m \n\u001B[1;32m  10995\u001B[0m \u001B[38;5;124;03m    Returns\u001B[39;00m\n\u001B[1;32m  10996\u001B[0m \u001B[38;5;124;03m    -------\u001B[39;00m\n\u001B[1;32m  10997\u001B[0m \u001B[38;5;124;03m    DataFrame\u001B[39;00m\n\u001B[1;32m  10998\u001B[0m \u001B[38;5;124;03m        Correlation matrix.\u001B[39;00m\n\u001B[1;32m  10999\u001B[0m \n\u001B[1;32m  11000\u001B[0m \u001B[38;5;124;03m    See Also\u001B[39;00m\n\u001B[1;32m  11001\u001B[0m \u001B[38;5;124;03m    --------\u001B[39;00m\n\u001B[1;32m  11002\u001B[0m \u001B[38;5;124;03m    DataFrame.corrwith : Compute pairwise correlation with another\u001B[39;00m\n\u001B[1;32m  11003\u001B[0m \u001B[38;5;124;03m        DataFrame or Series.\u001B[39;00m\n\u001B[1;32m  11004\u001B[0m \u001B[38;5;124;03m    Series.corr : Compute the correlation between two Series.\u001B[39;00m\n\u001B[1;32m  11005\u001B[0m \n\u001B[1;32m  11006\u001B[0m \u001B[38;5;124;03m    Notes\u001B[39;00m\n\u001B[1;32m  11007\u001B[0m \u001B[38;5;124;03m    -----\u001B[39;00m\n\u001B[1;32m  11008\u001B[0m \u001B[38;5;124;03m    Pearson, Kendall and Spearman correlation are currently computed using pairwise complete observations.\u001B[39;00m\n\u001B[1;32m  11009\u001B[0m \n\u001B[1;32m  11010\u001B[0m \u001B[38;5;124;03m    * `Pearson correlation coefficient <https://en.wikipedia.org/wiki/Pearson_correlation_coefficient>`_\u001B[39;00m\n\u001B[1;32m  11011\u001B[0m \u001B[38;5;124;03m    * `Kendall rank correlation coefficient <https://en.wikipedia.org/wiki/Kendall_rank_correlation_coefficient>`_\u001B[39;00m\n\u001B[1;32m  11012\u001B[0m \u001B[38;5;124;03m    * `Spearman's rank correlation coefficient <https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient>`_\u001B[39;00m\n\u001B[1;32m  11013\u001B[0m \n\u001B[1;32m  11014\u001B[0m \u001B[38;5;124;03m    Examples\u001B[39;00m\n\u001B[1;32m  11015\u001B[0m \u001B[38;5;124;03m    --------\u001B[39;00m\n\u001B[1;32m  11016\u001B[0m \u001B[38;5;124;03m    >>> def histogram_intersection(a, b):\u001B[39;00m\n\u001B[1;32m  11017\u001B[0m \u001B[38;5;124;03m    ...     v = np.minimum(a, b).sum().round(decimals=1)\u001B[39;00m\n\u001B[1;32m  11018\u001B[0m \u001B[38;5;124;03m    ...     return v\u001B[39;00m\n\u001B[1;32m  11019\u001B[0m \u001B[38;5;124;03m    >>> df = pd.DataFrame([(.2, .3), (.0, .6), (.6, .0), (.2, .1)],\u001B[39;00m\n\u001B[1;32m  11020\u001B[0m \u001B[38;5;124;03m    ...                   columns=['dogs', 'cats'])\u001B[39;00m\n\u001B[1;32m  11021\u001B[0m \u001B[38;5;124;03m    >>> df.corr(method=histogram_intersection)\u001B[39;00m\n\u001B[1;32m  11022\u001B[0m \u001B[38;5;124;03m          dogs  cats\u001B[39;00m\n\u001B[1;32m  11023\u001B[0m \u001B[38;5;124;03m    dogs   1.0   0.3\u001B[39;00m\n\u001B[1;32m  11024\u001B[0m \u001B[38;5;124;03m    cats   0.3   1.0\u001B[39;00m\n\u001B[1;32m  11025\u001B[0m \n\u001B[1;32m  11026\u001B[0m \u001B[38;5;124;03m    >>> df = pd.DataFrame([(1, 1), (2, np.nan), (np.nan, 3), (4, 4)],\u001B[39;00m\n\u001B[1;32m  11027\u001B[0m \u001B[38;5;124;03m    ...                   columns=['dogs', 'cats'])\u001B[39;00m\n\u001B[1;32m  11028\u001B[0m \u001B[38;5;124;03m    >>> df.corr(min_periods=3)\u001B[39;00m\n\u001B[1;32m  11029\u001B[0m \u001B[38;5;124;03m          dogs  cats\u001B[39;00m\n\u001B[1;32m  11030\u001B[0m \u001B[38;5;124;03m    dogs   1.0   NaN\u001B[39;00m\n\u001B[1;32m  11031\u001B[0m \u001B[38;5;124;03m    cats   NaN   1.0\u001B[39;00m\n\u001B[1;32m  11032\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m  \u001B[38;5;66;03m# noqa: E501\u001B[39;00m\n\u001B[1;32m  11033\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_numeric_data() \u001B[38;5;28;01mif\u001B[39;00m numeric_only \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n\u001B[1;32m  11034\u001B[0m     cols \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mcolumns\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:8885\u001B[0m, in \u001B[0;36mresample\u001B[0;34m(self, rule, axis, closed, label, convention, kind, on, level, origin, offset, group_keys)\u001B[0m\n\u001B[1;32m   8878\u001B[0m     \u001B[38;5;66;03m# GH 40420\u001B[39;00m\n\u001B[1;32m   8879\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwhere(subset, threshold, axis\u001B[38;5;241m=\u001B[39maxis, inplace\u001B[38;5;241m=\u001B[39minplace)\n\u001B[1;32m   8881\u001B[0m \u001B[38;5;129m@overload\u001B[39m\n\u001B[1;32m   8882\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mclip\u001B[39m(\n\u001B[1;32m   8883\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   8884\u001B[0m     lower\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m,\n\u001B[0;32m-> 8885\u001B[0m     upper\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m,\n\u001B[1;32m   8886\u001B[0m     \u001B[38;5;241m*\u001B[39m,\n\u001B[1;32m   8887\u001B[0m     axis: Axis \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m,\n\u001B[1;32m   8888\u001B[0m     inplace: Literal[\u001B[38;5;28;01mFalse\u001B[39;00m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m,\n\u001B[1;32m   8889\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m   8890\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Self:\n\u001B[1;32m   8891\u001B[0m     \u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m\n\u001B[1;32m   8893\u001B[0m \u001B[38;5;129m@overload\u001B[39m\n\u001B[1;32m   8894\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mclip\u001B[39m(\n\u001B[1;32m   8895\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   8901\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m   8902\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/resample.py:27\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_libs\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m lib\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_libs\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtslibs\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m     19\u001B[0m     BaseOffset,\n\u001B[1;32m     20\u001B[0m     IncompatibleFrequency,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     25\u001B[0m     to_offset,\n\u001B[1;32m     26\u001B[0m )\n\u001B[0;32m---> 27\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_libs\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtslibs\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdtypes\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m freq_to_period_freqstr\n\u001B[1;32m     28\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_typing\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m NDFrameT\n\u001B[1;32m     29\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcompat\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m function \u001B[38;5;28;01mas\u001B[39;00m nv\n",
      "\u001B[0;31mImportError\u001B[0m: cannot import name 'freq_to_period_freqstr' from 'pandas._libs.tslibs.dtypes' (/Users/sjoerd/anaconda3/lib/python3.11/site-packages/pandas/_libs/tslibs/dtypes.cpython-311-darwin.so)"
     ]
    }
   ],
   "source": [
    "# loading dataframes \n",
    "\n",
    "url = 'https://github.com/Sebasleen/Seminargroup/raw/Seminar/Data/managed_portfolios_anom_d_55.csv'\n",
    "\n",
    "r_daily = pd.read_csv(url)\n",
    "\n",
    "# drop all momentum factors or factors that are constructed based on momentum (including market return variables)\n",
    "\n",
    "factor_drop_list = ['r_mom', 'r_indmom', 'r_valmom', 'r_valmomprof', 'r_mom12', 'r_momrev', 'r_indmomrev', 'r_exchsw', 'rme', 're_ew']\n",
    "\n",
    "r_daily.drop(columns=factor_drop_list, inplace=True)\n",
    "\n",
    "# set date to datetime format and set the date to the index \n",
    "\n",
    "r_daily['date'] = pd.to_datetime(r_daily['date'])\n",
    "r_daily.set_index('date', inplace=True)\n",
    "\n",
    "# following the procedure in the paper, if there are observations missing we set them to 0. (footnote 16)\n",
    "\n",
    "r_daily.fillna(0, inplace=True)\n",
    "\n",
    "# create a list of factors for later analysis purposes \n",
    "\n",
    "factors = [col for col in r_daily.columns if col.startswith('r_')]\n",
    "\n",
    "# create a monthly return dataframe for later analysis purposes (by summing the daily returns)\n",
    "\n",
    "r_monthly = r_daily.resample('M').sum()\n",
    "r_monthly.index = r_monthly.index.strftime('%Y-%m')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T13:35:25.095180Z",
     "start_time": "2024-02-26T13:35:19.097990Z"
    }
   },
   "id": "53b534a6439d1efb",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "6c93e32e30ad672c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
