{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739a1c2a-3ad4-4c2a-8db1-7663ea485f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "import pandas as pd\n",
    "import calendar\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "from scipy.interpolate import interp1d\n",
    "from joblib import delayed, Parallel\n",
    "from sklearn.metrics import silhouette_score\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "from sklearn.manifold import TSNE\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331c4063-ae8d-4779-8acd-fa3f5e0cdcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# De dataset, ik kreeg niet de raw.githubusercontent gebeuren gefixt dus is gewoon via m'n laptop.\n",
    "\n",
    "#url = 'https://raw.githubusercontent.com/Sebasleen/Seminargroup/Seminar/managed_portfolios_anom_d_50.csv'\n",
    "#url = 'https://github.com/Sebasleen/Seminargroup/blob/63818bef83c627710fdd0fed246c51065ab98216/managed_portfolios_anom_d_55.csv'\n",
    "kmeans1 = pd.read_csv('/Users/sebasleen/Downloads/managed_portfolios_anom_d_55.csv')\n",
    "\n",
    "print(kmeans1.columns)\n",
    "#Dropping the rme & re_ew columns as these are irrelevant. As well as the momentum returns and exchsw.\n",
    "kmeans1.drop(columns=['r_mom', 'r_indmom', 'r_valmom', 'r_valmomprof', 'r_mom12', 'r_momrev', 'r_indmomrev', 'r_exchsw', 'rme', 're_ew'], inplace=True)\n",
    "\n",
    "#Convert date to datetime and setting it as the index given that we have time-senitive data\n",
    "kmeans1['date'] = pd.to_datetime(kmeans1['date'])\n",
    "kmeans1.set_index('date', inplace=True)\n",
    "\n",
    "#The NaN are set to 0 as in the original research\n",
    "kmeans1.fillna(0, inplace=True)\n",
    "\n",
    "#Making sure that all the columns are numerical that are left\n",
    "numerical_columns = kmeans1.columns\n",
    "\n",
    "#We use robustscaler because of the number of outliers (1643 on the dataset of 13719)\n",
    "scaler = RobustScaler()\n",
    "kmeans1[numerical_columns] = scaler.fit_transform(kmeans1[numerical_columns])\n",
    "\n",
    "#Print the dataframe for debugging purposes and seeing that it goes well so far\n",
    "print(\"Kmeans clustering dataframe:\")\n",
    "print(kmeans1)\n",
    "\n",
    "#Dit is de code die kijkt of er outliers zijn.\n",
    "\n",
    "#summary_stats = kmeans1.describe()\n",
    "#\n",
    "## Plot boxplots\n",
    "#kmeans1.boxplot()\n",
    "#plt.title('Boxplot of Numerical Columns')\n",
    "#plt.show()\n",
    "#\n",
    "## Plot histograms\n",
    "#kmeans1.hist()\n",
    "#plt.title('Histogram of Numerical Columns')\n",
    "#plt.show()\n",
    "#\n",
    "## Calculate Z-scores\n",
    "#z_scores = (kmeans1 - kmeans1.mean()) / kmeans1.std()\n",
    "#\n",
    "## Define threshold for outliers (e.g., Z-score > 3)\n",
    "#outlier_threshold = 3.5\n",
    "#\n",
    "## Find outliers\n",
    "#outliers = (z_scores > outlier_threshold) | (z_scores < -outlier_threshold)\n",
    "#outliers_count = outliers.sum()\n",
    "#\n",
    "#print(\"Outliers count per column:\")\n",
    "#print(outliers_count)\n",
    "#\n",
    "\n",
    "#Oke ik ga niet interpolaten gezien de dagen waar niet op werd getrade veelal feestdagen waren\n",
    "\n",
    "\n",
    "#Given that we have missing days, we think it would be beneifical to interpolate these using spline interpolation.\n",
    "#We use spline because it fits well with our time-sensitive and non-linear datapoints.\n",
    "##We make sure to exclude weekends for interpolation because there are no returns then.\n",
    "#all_dates = pd.date_range(start=kmeans1.index.min(), end=kmeans1.index.max())\n",
    "#dates = pd.date_range(start=kmeans1.index.min(), end=kmeans1.index.max())\n",
    "#weekdays = all_dates[dates.dayofweek < 5]  # Monday to Friday\n",
    "#missing_dates = weekdays.difference(kmeans1.index)\n",
    "#\n",
    "#interpolated_df = pd.DataFrame(index=missing_dates)\n",
    "#\n",
    "##Perform spline interpolation for every weekday that is missing\n",
    "#for column in kmeans1.columns:\n",
    "#    non_missing_dates = kmeans1[column].dropna()\n",
    "#    non_missing_dates = non_missing_dates.sort_index()\n",
    "#    spline_interpolator = interp1d((non_missing_dates.index - datetime(1970, 1, 1)).days.values,\n",
    "#                                   non_missing_dates.values, kind='cubic', fill_value='extrapolate')\n",
    "#    interpolated_values = spline_interpolator((missing_dates - datetime(1970, 1, 1)).days.values)\n",
    "#    interpolated_df[column] = interpolated_values\n",
    "\n",
    "#Readding the interpolated data back into the original kmeans dataframe\n",
    "#kmeans_interpolated = pd.concat([kmeans1, interpolated_df])\n",
    "#kmeans_interpolated.sort_index(inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accc8a43-7d74-4893-bcd3-b691f28445b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Noge ven kijken wat zij doen met de data van factors die pas later beginnen\n",
    "first_return_dates = kmeans1.apply(lambda x: x[x != 0].index[0] if any(x != 0) else None)\n",
    "\n",
    "# Print the result\n",
    "print(\"First return dates for each factor:\")\n",
    "print(first_return_dates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5efbac5-3c65-436a-9469-310ecdc21147",
   "metadata": {},
   "source": [
    "Here we do a lot of testing to see whether monthly or daily data has better elbow and silhouette scores for the number of clusters.\n",
    "\n",
    "First monthly then daily.\n",
    "\n",
    "We can safely assume that the optimal number is 4 and the optimal data is daily.\n",
    "\n",
    "The code is put in another file to save space and processing power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bb7ecf-3a1a-46fa-95ff-0a4956095373",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here clustering per month using the daily data which has not been interpolated\n",
    "\n",
    "# Assuming optimal number of clusters\n",
    "num_clusters = 4  # Adjust this as needed\n",
    "\n",
    "# Define the threshold for considering weights close to 0\n",
    "weight_threshold = 0.05\n",
    "\n",
    "# Dictionary to store cluster assignments for each month\n",
    "monthly_cluster_assignments = {}\n",
    "\n",
    "# Iterate over each month in the DataFrame\n",
    "for month, data in kmeans1.groupby(pd.Grouper(freq='M')):\n",
    "    # Perform K-means clustering for the current month\n",
    "    kmeans_model = KMeans(n_clusters=num_clusters, random_state=69)\n",
    "    cluster_assignments = kmeans_model.fit_predict(data)\n",
    "    \n",
    "    # Store cluster assignments and centroids for the current month\n",
    "    cluster_centers = kmeans_model.cluster_centers_\n",
    "    \n",
    "    # Filter factors with weights close to 0 for each cluster\n",
    "    filtered_centers = []\n",
    "    for centroid in cluster_centers:\n",
    "        filtered_centroid = np.array([weight if abs(weight) > weight_threshold else 0 for weight in centroid])\n",
    "        filtered_centers.append(filtered_centroid)\n",
    "    filtered_centers = np.array(filtered_centers)\n",
    "    \n",
    "    monthly_cluster_assignments[month] = (cluster_assignments, filtered_centers)\n",
    "\n",
    "# Create a list of factor numbers (indices)\n",
    "factor_indices = list(range(1, len(data.columns) + 1))\n",
    "\n",
    "# Visualize all clusters for each month\n",
    "for month, (cluster_assignments, cluster_centers) in monthly_cluster_assignments.items():\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.title(f'Clusters for {month}')\n",
    "    plt.xlabel('Factor Number')\n",
    "    plt.ylabel('Factor Weight')\n",
    "    \n",
    "    # Initialize an array to store the maximum absolute weight for each factor\n",
    "    max_abs_weights = np.zeros(len(factor_indices))\n",
    "    \n",
    "    # Initialize an array to store the cluster ID with maximum weight for each factor\n",
    "    max_weight_cluster = np.zeros(len(factor_indices), dtype=int)\n",
    "    \n",
    "    # Determine the maximum absolute weight and corresponding cluster ID for each factor\n",
    "    for factor_index in range(len(factor_indices)):\n",
    "        max_abs_weight = 0\n",
    "        for cluster_id in range(num_clusters):\n",
    "            weight = cluster_centers[cluster_id][factor_index]\n",
    "            if abs(weight) > abs(max_abs_weight):\n",
    "                max_abs_weight = weight\n",
    "                max_weight_cluster[factor_index] = cluster_id + 1  # Cluster ID starts from 1\n",
    "        max_abs_weights[factor_index] = max_abs_weight\n",
    "    \n",
    "    # Plot the factors with their maximum absolute weights\n",
    "    for cluster_id in range(1, num_clusters + 1):\n",
    "        cluster_weights = np.where(max_weight_cluster == cluster_id, max_abs_weights, 0)\n",
    "        plt.scatter(factor_indices, cluster_weights, marker='o', label=f'Cluster {cluster_id}')\n",
    "    \n",
    "    # Annotate each point with its factor number\n",
    "    for i, txt in enumerate(factor_indices):\n",
    "        for cluster_id in range(1, num_clusters + 1):\n",
    "            weight = max_abs_weights[i]\n",
    "            if weight != 0:  # Exclude factors with weights below the threshold\n",
    "                plt.annotate(txt, (factor_indices[i], weight), textcoords=\"offset points\", xytext=(0,10), ha='center')\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492af9ae-bdba-4727-ac45-23a58d14256f",
   "metadata": {},
   "source": [
    "Dit is eigenlijk waar alles wat er in de graphs hierboven staat wordt omgezet in strings. Dus voor elke maand voor cluster geeft die aan welke factors daarin zitten en  welke weights zij hebben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171230ce-717f-4fa9-a7f5-ac1db287fac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_monthly_cluster_factor_values(kmeans1, num_clusters=4, weight_threshold=0.05):\n",
    "    # Dictionary to store cluster factor values for each month\n",
    "    monthly_cluster_factor_values = {}\n",
    "\n",
    "    # Iterate over each month in the DataFrame\n",
    "    for month, (cluster_assignments, cluster_centers) in monthly_cluster_assignments.items():\n",
    "        # Initialize a dictionary to store factor values for each cluster\n",
    "        cluster_factor_values = {}\n",
    "\n",
    "        # Initialize arrays to store factor indices and weights for each cluster\n",
    "        factor_indices_list = [[] for _ in range(num_clusters)]\n",
    "        factor_weights_list = [[] for _ in range(num_clusters)]\n",
    "\n",
    "        # Determine the cluster with the maximum absolute weight for each factor\n",
    "        max_weight_cluster = np.argmax(np.abs(cluster_centers), axis=0) + 1  # Cluster ID starts from 1\n",
    "        max_abs_weights = np.max(np.abs(cluster_centers), axis=0)\n",
    "\n",
    "        # Store factor values for each cluster\n",
    "        for factor_index in range(len(factor_indices)):\n",
    "            cluster_id = max_weight_cluster[factor_index]\n",
    "            weight = cluster_centers[cluster_id - 1][factor_index]  # Cluster ID starts from 1\n",
    "            if abs(weight) > weight_threshold:\n",
    "                factor_indices_list[cluster_id - 1].append(factor_index + 1)  # Factor indices start from 1\n",
    "                factor_weights_list[cluster_id - 1].append(weight)\n",
    "\n",
    "        # Store cluster factor values for the current month\n",
    "        for cluster_id in range(num_clusters):\n",
    "            cluster_factor_values[cluster_id + 1] = {'factor_indices': factor_indices_list[cluster_id],\n",
    "                                                     'factor_weights': factor_weights_list[cluster_id]}\n",
    "        \n",
    "        monthly_cluster_factor_values[month] = cluster_factor_values\n",
    "\n",
    "    return monthly_cluster_factor_values\n",
    "\n",
    "# Call the function to compute and store the monthly cluster factor values\n",
    "monthly_cluster_factor_weights = compute_monthly_cluster_factor_values(kmeans1)\n",
    "\n",
    "\n",
    "print(monthly_cluster_factor_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8cf72c-2b4d-4bf1-ab54-2573cc899a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hier worden ze gescaled en gedemeaned. Wat je kan zien is dat de datapunten nogal veranderen.\n",
    "\n",
    "def scale_and_demean_factors(monthly_cluster_factor_values):\n",
    "    # Dictionary to store scaled and demeaned factor values for each month\n",
    "    scaled_demeaned_factors = {}\n",
    "\n",
    "    # Compute mean and standard deviation for each factor\n",
    "    factor_means = {}\n",
    "    factor_stddevs = {}\n",
    "    for month_factors in monthly_cluster_factor_values.values():\n",
    "        for cluster_factors in month_factors.values():\n",
    "            for factor_index, factor_weight in zip(cluster_factors['factor_indices'], cluster_factors['factor_weights']):\n",
    "                if factor_index not in factor_means:\n",
    "                    factor_means[factor_index] = []\n",
    "                    factor_stddevs[factor_index] = []\n",
    "                factor_means[factor_index].append(factor_weight)\n",
    "    \n",
    "    for factor_index, values in factor_means.items():\n",
    "        factor_means[factor_index] = np.mean(values)\n",
    "        factor_stddevs[factor_index] = np.std(values)\n",
    "\n",
    "    # Scale and demean factor values for each month\n",
    "    for month, month_factors in monthly_cluster_factor_values.items():\n",
    "        scaled_demeaned_factors[month] = {}\n",
    "        for cluster_id, cluster_factors in month_factors.items():\n",
    "            scaled_demeaned_factors[month][cluster_id] = {}\n",
    "            for factor_index, factor_weight in zip(cluster_factors['factor_indices'], cluster_factors['factor_weights']):\n",
    "                scaled_weight = (factor_weight - factor_means[factor_index]) / factor_stddevs[factor_index]\n",
    "                scaled_demeaned_factors[month][cluster_id][factor_index] = scaled_weight\n",
    "\n",
    "    return scaled_demeaned_factors\n",
    "\n",
    "# Call the function to scale and demean factor values\n",
    "scaled_demeaned_factors = scale_and_demean_factors(monthly_cluster_factor_values)\n",
    "\n",
    "print(scaled_demeaned_factors)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
